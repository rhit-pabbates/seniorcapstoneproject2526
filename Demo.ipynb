{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2566f6",
   "metadata": {},
   "source": [
    "\n",
    "# Tensor-based analysis of Elliptic dataset (DEMO) - Ethan Pabbathi\n",
    "-----\n",
    "\n",
    "## 1\\. What is a Tensor? (The Data Cube)\n",
    "\n",
    "### Mathematical Theory\n",
    "\n",
    "At its core, a tensor is a multi-dimensional array of numbers. You're already familiar with the first two orders:\n",
    "\n",
    "  * A **1st-order tensor** is a **vector** (a single list of numbers).\n",
    "  * A **2nd-order tensor** is a **matrix** (a grid of numbers, like a spreadsheet).\n",
    "  * A **3rd-order tensor**, which we use in this project, is like a **cube of numbers**.\n",
    "\n",
    "In our project, we model the transaction data as a 3rd-order tensor where the dimensions are **(Senders, Receivers, Time)**. Each cell `T[i, j, k]` in this cube represents the transaction amount from sender `i` to receiver `j` at time `k`.\n",
    "\n",
    "This structure is powerful because it preserves the complete relationship between entities, unlike a simple 2D matrix which would force us to lose the time dimension. The concept of **tensor rank** is the smallest number of simple, rank-1 tensors that can be summed up to produce the original tensor. This idea is central to decomposition.\n",
    "\n",
    "### How it Relates to the Code\n",
    "\n",
    "In the script, this is the first thing we do:\n",
    "\n",
    "```python\n",
    "# Create an empty 3D tensor (our \"data cube\")\n",
    "tensor = np.zeros((num_senders, num_receivers, num_timesteps))\n",
    "\n",
    "# Plant patterns by assigning values to specific T[i, j, k] coordinates\n",
    "tensor[8, 9, 3] = 100.0\n",
    "```\n",
    "\n",
    "We build a 3D `numpy` array and \"plant\" patterns by placing values at specific `(sender, receiver, time)` coordinates. This simulates the real-world data structure.\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. Tucker Decomposition (High-Level Compression)\n",
    "\n",
    "### Mathematical Theory\n",
    "\n",
    "Tucker decomposition is a method for compressing a tensor into a smaller **core tensor** and a set of **factor matrices**, one for each dimension. Think of it as a more powerful version of Principal Component Analysis (PCA) for multi-dimensional data.\n",
    "\n",
    "The formula is:\n",
    "$X \\approx G \\times_1 A \\times_2 B \\times_3 C$\n",
    "\n",
    "Where:\n",
    "\n",
    "  * $X$ is the original, large tensor.\n",
    "  * $G$ is the small, compressed core tensor. It captures the high-level interactions between the groups found in the factor matrices.\n",
    "  * $A, B, C$ are the factor matrices for senders, receivers, and time, respectively. They act as \"dictionaries\" that describe the archetypal groups within each dimension.\n",
    "\n",
    "### How it Relates to the Code\n",
    "\n",
    "This is performed with a single function call:\n",
    "\n",
    "```python\n",
    "# The rank determines the size of the compressed core tensor\n",
    "core, factors = tucker(transaction_tensor_tl, rank=[2, 2, 2])\n",
    "```\n",
    "\n",
    "  * `rank=[2, 2, 2]`: We are telling Tucker to find the **2 most dominant archetypal groups** for senders, the 2 most for receivers, and the 2 most for time.\n",
    "  * `core`: This is our small summary tensor `G`. Its shape `(2, 2, 2)` shows it's a compressed version of the original.\n",
    "  * `factors`: This is the list containing our factor matrices `A`, `B`, and `C`. The sender factor matrix, for example, will have a shape of `(10, 2)`, mapping our 10 original senders to the 2 archetypal sender groups.\n",
    "\n",
    "**Use Case**: Tucker is excellent for denoising data and getting a high-level, structural overview of the transaction network.\n",
    "\n",
    "-----\n",
    "\n",
    "## 3\\. PARAFAC/CP Decomposition (Extracting Specific Patterns)\n",
    "\n",
    "### Mathematical Theory\n",
    "\n",
    "PARAFAC, also known as Canonical Polyadic (CP) decomposition, is a more direct and often more interpretable method. It breaks down the tensor into a sum of a fixed number of **rank-1 tensors**.\n",
    "\n",
    "A rank-1 tensor is simply the outer product of three vectors. So, for a `rank=R` decomposition, the formula is:\n",
    "$X \\approx \\sum_{r=1}^{R} \\lambda_r \\cdot (\\mathbf{a}_r \\circ \\mathbf{b}_r \\circ \\mathbf{c}_r)$\n",
    "\n",
    "Where:\n",
    "\n",
    "  * $R$ is the number of patterns we want to find.\n",
    "  * For each pattern $r$, we get three vectors: $\\mathbf{a}_r$ (sender involvement), $\\mathbf{b}_r$ (receiver involvement), and $\\mathbf{c}_r$ (time involvement).\n",
    "  * $\\lambda_r$ is a weight that indicates the overall importance of pattern $r$.\n",
    "\n",
    "The key advantage here is that each component is a directly readable **\"who â†’ whom â†’ when\"** pattern.\n",
    "\n",
    "### How it Relates to the Code\n",
    "\n",
    "The implementation is also a single line, but the interpretation is different:\n",
    "\n",
    "```python\n",
    "# We use rank=2 because we want to find the two patterns we created.\n",
    "weights, factors = parafac(transaction_tensor_tl, rank=2, ...)\n",
    "sender_factors, receiver_factors, timestep_factors = factors\n",
    "```\n",
    "\n",
    "  * `rank=2`: We are explicitly telling the model to find the **2 most significant, distinct transaction behaviors** in the data.\n",
    "  * `factors`: This is a list of matrices. `sender_factors` has a shape of `(10, 2)`. **Crucially, the first column is the vector $\\mathbf{a}_1$ (sender part of Pattern 1), and the second column is the vector $\\mathbf{a}_2$ (sender part of Pattern 2).**\n",
    "  * The output is a set of vectors that directly describe the patterns, making it perfect for identifying specific illicit activities.\n",
    "\n",
    "### Interpreting the Results\n",
    "\n",
    "To find the epicenter of a pattern, we simply find the element with the highest value in each corresponding factor vector.\n",
    "\n",
    "```python\n",
    "# Find the index of the max value in the first column (Pattern 1)\n",
    "dominant_sender = np.argmax(sender_factors[:, 0])\n",
    "```\n",
    "\n",
    "This is how the script successfully pinpoints the planted patterns. It looks at the vectors for the first component and finds that Sender 9, Receiver 9, and Timestep 3 have the highest scores, perfectly matching our \"illicit money drop\" pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036711ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ”¬ Creating a Mock Dataset with Planted Patterns ---\n",
      "Planting illicit pattern: Senders 8, 9 -> Receiver 9 @ Time 3\n",
      "Planting licit pattern: Sender 0 -> Various Receivers @ All Times\n",
      "\n",
      "Mock tensor created with shape: (10, 10, 5)\n",
      "\n",
      "---  compressing with Tucker Decomposition ---\n",
      "Shape of compressed core tensor: (2, 2, 2)\n",
      "Tucker has summarized the data into its 2 most dominant sender-groups, receiver-groups, and time-groups.\n",
      "\n",
      "--- ðŸ”Ž Extracting Patterns with PARAFAC Decomposition ---\n",
      "\n",
      "--- âœ… Interpretation of Results ---\n",
      "\n",
      "--- Analyzing Discovered Pattern #1 ---\n",
      "Most Dominant Sender: 9\n",
      "Most Dominant Receiver: 9\n",
      "Most Dominant Timestep: 3\n",
      "Conclusion: This pattern matches our 'Illicit Money Drop'!\n",
      "\n",
      "--- Analyzing Discovered Pattern #2 ---\n",
      "Most Dominant Sender: 0\n",
      "Most Dominant Receiver: 3\n",
      "Most Dominant Timestep: 0\n",
      "Conclusion: This pattern matches our 'Licit Exchange'!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker, parafac\n",
    "\n",
    "# --- 1. Create a Mock Dataset ---\n",
    "# We'll create a small world with 10 senders, 10 receivers, and 5 timesteps.\n",
    "num_senders = 10\n",
    "num_receivers = 10\n",
    "num_timesteps = 5\n",
    "\n",
    "# Create an empty 3D tensor (our \"data cube\")\n",
    "# We'll use floats to represent transaction amounts.\n",
    "tensor = np.zeros((num_senders, num_receivers, num_timesteps))\n",
    "\n",
    "print(\"--- ðŸ”¬ Creating a Mock Dataset with Planted Patterns ---\")\n",
    "\n",
    "# Plant Pattern 1: An \"Illicit Money Drop\"\n",
    "# Two suspicious senders (8 and 9) send large amounts to one receiver (9)\n",
    "# specifically at timestep 3. This is a coordinated, hidden pattern.\n",
    "print(\"Planting illicit pattern: Senders 8, 9 -> Receiver 9 @ Time 3\")\n",
    "tensor[8, 9, 3] = 100.0  # Sender 8 -> Receiver 9\n",
    "tensor[9, 9, 3] = 120.0  # Sender 9 -> Receiver 9\n",
    "\n",
    "# Plant Pattern 2: A \"Licit Exchange\"\n",
    "# A major exchange (Sender 0) sends regular, smaller amounts to many\n",
    "# different receivers across all timesteps. This is a normal, noisy pattern.\n",
    "print(\"Planting licit pattern: Sender 0 -> Various Receivers @ All Times\")\n",
    "tensor[0, 0:5, :] = 15.0  # Sender 0 -> Receivers 0-4 at all times\n",
    "\n",
    "# Add some random noise to make it realistic\n",
    "tensor += np.random.rand(num_senders, num_receivers, num_timesteps) * 2.0\n",
    "\n",
    "# Convert to a TensorLy tensor object for our analysis\n",
    "transaction_tensor_tl = tl.tensor(tensor)\n",
    "print(f\"\\nMock tensor created with shape: {transaction_tensor_tl.shape}\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Tucker Decomposition (The High-Level Summary) ---\n",
    "# Tucker finds the main \"ingredients\" of the data. It compresses the tensor\n",
    "# into a smaller core and factor matrices representing archetypal groups.\n",
    "print(\"---  compressing with Tucker Decomposition ---\")\n",
    "core, factors = tucker(transaction_tensor_tl, rank=[2, 2, 2])\n",
    "print(f\"Shape of compressed core tensor: {core.shape}\")\n",
    "print(\"Tucker has summarized the data into its 2 most dominant sender-groups, receiver-groups, and time-groups.\\n\")\n",
    "\n",
    "\n",
    "# --- 3. PARAFAC/CP Decomposition (Finding Specific Patterns) ---\n",
    "# PARAFAC is designed to extract a specific number of distinct patterns.\n",
    "# Since we planted 2 patterns, we ask it to find 2.\n",
    "print(\"--- ðŸ”Ž Extracting Patterns with PARAFAC Decomposition ---\")\n",
    "# We use rank=2 because we want to find the two patterns we created.\n",
    "weights, factors = parafac(transaction_tensor_tl, rank=2, init='random', random_state=42)\n",
    "sender_factors, receiver_factors, timestep_factors = factors\n",
    "\n",
    "\n",
    "# --- 4. Interpreting the Discovered Patterns ---\n",
    "print(\"\\n--- âœ… Interpretation of Results ---\")\n",
    "# The algorithm doesn't know which pattern is which, so we check both.\n",
    "for i in range(2):\n",
    "    print(f\"\\n--- Analyzing Discovered Pattern #{i+1} ---\")\n",
    "\n",
    "    # Find the sender, receiver, and timestep most involved in this pattern\n",
    "    dominant_sender = np.argmax(sender_factors[:, i])\n",
    "    dominant_receiver = np.argmax(receiver_factors[:, i])\n",
    "    dominant_timestep = np.argmax(timestep_factors[:, i])\n",
    "\n",
    "    print(f\"Most Dominant Sender: {dominant_sender}\")\n",
    "    print(f\"Most Dominant Receiver: {dominant_receiver}\")\n",
    "    print(f\"Most Dominant Timestep: {dominant_timestep}\")\n",
    "\n",
    "    # Check if the discovered pattern matches one we planted\n",
    "    if dominant_sender in [8, 9] and dominant_receiver == 9 and dominant_timestep == 3:\n",
    "        print(\"Conclusion: This pattern matches our 'Illicit Money Drop'!\")\n",
    "    elif dominant_sender == 0:\n",
    "        print(\"Conclusion: This pattern matches our 'Licit Exchange'!\")\n",
    "    else:\n",
    "        print(\"Conclusion: This pattern is a mix of other behaviors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
